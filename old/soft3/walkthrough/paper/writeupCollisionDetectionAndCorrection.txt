) Setup

The path of the camera has two separate parts, position and orientation.  Both of these parts are specified by keyframes.  Each keyframe is a point in space with an attached orientation.  We choose to represent the orientations as quaternions.  Typically, orientaion would be represented by a rotation matrix, however, quaternions are more robust and more natural to interpolate between than rotation matrices.   To review, a quaternion is defined as an ordered pair (s,v) where s is a scalar and v is a 3-vector and s^2+v.v = 1.  Because of the second condition, it follows that quaternions are also points on S^3.  Quaternions encode rotation around an arbitrary axis.
	The model that we will be moving the virtual camera around is a general polyhedral mesh.  For simplicity in the intersection algorithm, the mesh will be reduced to a triangular mesh.  The set of triangles in the scene will be referred to as T_s.
	An initial path for the camera is constructed by building a bezier, B(t), spline through the positions of the positions specified by the keyframes and a quaternion spline, Q(t), through the orientations specified by the keyframes.  At any parameter value t, B(t) and Q(t) completely describe the location of the camera in space.

2) Camera Model

Camera model stuff that I haven't gotten yet..mainly important to talk about image plane as the area of interest for collision with the camera, the camera parameters, the math that finds the corners, and the glfrustum command for setting the parameters

3) Collision Detection

As the camera moves along B(t) with orientation Q(t), what constitutes a collision?  At any parameter value, if a triangle intersects the image plane, also called the near clipping plane, then it is in essence poking through the lens of our camera and is a collision that must be avoided.  So as the camera flies along this path, the image plane sweeps out a volume.  Any scene geometry that intersects with this volume collides with the camera and must be avoided.

At a high level, there are two types of intersections that must be dealt with.  The first and most common type of intersection is one that pokes through a side of the volume.  The second type of intersection is an object that is completely enclosed by the volume.  Finding the first type of collision only requires intersecting the scene with the surface of the volume.  We can construct this surface by developing curves for the four corners of the image plane as it sweeps along B(t) with orientation Q(t) and lofting surfaces between adjacent corner curves.   Using methods described in (Johnstone and Williams paper), these four corner curves can be constructed.

Some discussion of the techniques?  Talk about knots of corner curves for reference later...call curves C_1 .. C_4.  C_1 = upper left, rest are ccw order.

With the corner curves constructed, we now triangulate between adjacent curves to make the surface.  By adjacent we mean curves that correspond to adjacent vertices on the image plane.  Triangles are constructed by sampling along the curves at a constant rate and putting a triangle strip between the samples.  Since we have the entire curve at hand, we have considered curvature based sampling for the most accurate representation of the surface.  This can become difficult because adjacent curves do not necessarily have similar curvatures.  For future work we consider finding a set of parameter values based on curvature to sample on for each curve.  When lofting a surface between two curves, the union of the sets of parameter values is used to sample each curve.  The triangles that compose the surface are stored.  We will refer to  this set of triangles as T_p.

The second type of collision, when an object is completely inside of the volume is more difficult to test for collisions.  To do so, we compute the image plane at some constant sampling rate by forming quadrilaterals with vertices C_1(t), C_2(t), C_3(t), and C_4(t).   Any geometry that intersects these quadrilaterals collides with the image plane.  These quadrilaterals are then broken into triangles that are added to the set  T_p.  Finding collisions is now just a matter of intersecting T_p with T_s.  Even simple scenes will likely have thousands of triangles.

To discuss the collision detection, first the octree data structure must be explained.  In general it is an 8-ary tree.  Each node of the tree represents some part of the space.  The root node represents the entire space.  For our case, scene vertices are scaled down to the unit cube, so the root node represents the entire cube.  Each node also has two lists of triangles.  One is the list of triangles from the scene (O_s) and the other  contains triangles from the ruled surface of the path (O_p).  O_s has a fixed size that is set by the user (the optimal size for this is difficult to determine), but O_p does not.  The general Idea is that we want to limit the number of intersection calculations to perform per triangle in T_s.  When a triangle is inserted into O_s, the triangle is simply inserted into the first open spot of the array.  If the result of inserting into O_s causes O_s to be full, then 8 child nodes are attached to the current node.  Each of these 8 child nodes correspond to an octant of the parent node.  Triangles from O_s and O_p of the parent node are distributed to the proper child nodes.  If a triangle lies in multiple octants, then the complete triangle is sent to multiple child nodes.  This does cause some duplication of data, but it is unavoidable.  Note that there is no subdivision when triangles are inserted into O_p.  When new triangles are inserted into the tree, if the root node has been subdivided, then the triangle is recursively inserted into the child nodes whose space the triangle exists in.  The effect of this data structure is that we greatly reduce the number of triangles that each triangle in T_s must be compared to.

In general, we want to isolate intervals, I, of B(t) over which there is a collision.  The first step in finding the interval is inserting all of T_s into O_s.  Now, the triangles of T_p are inserted into O_p.  However, the order in which T_p are inserted is important.  We want to find the first collision and correct it before moving on to the rest of the path.  To accomplish this, we insert the triangles in order of their parameter value on the corner curves.  Each vertex of each triangle of T_p is a point on one of the corner curves.  So we can insert the triangles in order of the minimum parameter value vertex of the triangle.  Rather than actually performing a sort, we just generate the triangles in the proper order and insert a triangle once it is calculated.  It is then tested for intersection with every element of O_s in that node.  This insertion in order of parameter continues until an intersection occurs.

When we find an intersection at some value s=s_1, we now have a parameter value that is in I.  We also know that the previous parameter value we tested at, s_0, had no intersection.  We want to find the exact parameter value where the collision begins.  So we perform a binary search between s_0 and s_1.  Like the standard binary search, we want to see what side of the mid point the intersection lies on.  We calculate the image plane at s_mid= (s_0 + s_1) / 2 and test for intersections with the scene.  If the test returns no intersection, then we recursively search on the interval from s_mid to s_1.  Otherwise we search from s_0 to s_mid.  When the bounds become close, within some epsilon, we stop the computation.  The result of the search is the true initial parameter value.

We then continue inserting triangles into the octree until there is no longer an intersection.  Then we have the same condition as above.  We have one value where there is an intersection, one value where there is none, and we need to find the exact value where the collision ends.  We repeat the above binary search to find the value.  With the parameter interval at hand, we can move on to correcting the path over that interval.


Correction:

Our method for correcting the path over the computed interval will be to introduce some number of new keyframes over this interval to push the curve into the proper region.  We know by the specifications of the problem, that each currently existing keyframe is in a valid position and orientation.  So by introducing more valid keyframes into the problematic interval, we ought to be able to correct the path.  Remember that to define a new keyframe, we have to consider both a new position and a new orientation.

The general strategy for computing a new position is to choose a point on the original curve, compute the image plane at that point on the curve, find where it intersects the scene geometry, and then move it away from those intersections.  The point that we choose is at the midpoint of the intersection interval, I.  So we compute m=(I_0 + I_1)/2  as the midpoint.  A minor problem arises here.  The intersection interval is calculated in the parameter of the corner curves.  To find the point on the position curve, we need a value in its parameter.  Even though the corner curves are parameterized differently, we can use the fact that they have the same number of knots as the original position curve to find the corresponding parameter using linear interpolation.  First find the knot values k_i and k_i+1 that the parameter lies between.  Then solve s = (m-k_i+1) / (k_i – k_i+1) to find the parameter of the value along that interval.  Then we can take the corresponding knots on the B(t) and use linear interpolation to find the parameter value, t_mid, which we in turn can use to find the position P_mid = B(t_mid).

Now we need to find the image plane when the camera is at B(t_mid).  Even though we just went through that trouble to get t_mid, the image plane is most easily calculated by connecting the points at c_1(s_mid)...c_4(s_mid).  We intersect line segments from the center of the image plane to each of the corners with the scene.  If there is an intersection along that segment, then we consider that vertex to be inside the scene and store it in a list ,IN.  We take vectors from the center of the image plane to the corners not in IN and average them, giving them the direction we ought to move the keyframe, V.

But how much do we need to move the keyframe?  If the collision is shallow, then we should not move much at all, but if the collision is deep then we will need to move quite a bit.  We need to calculate some sort of depth of collision, D, to scale V by.  To do this, we intersect the edges of the image plane with the scene and record the parameter value on the line segment that each intersection occurs at.  Using these parameter values we can calculate the distance from each vertex to its closest intersection.  We take the maximum such distance and use that to approximate the depth of the intersection, d.  So then the position of our new keyframe is at P_mid + dV.  Note that this approximation for the d and the somewhat imprecise direction to push the keyframe along means that the new keyframe may still be intersecting the screen.  The only thing that we can guarantee is that in some sense it is moving away from the collision in a direction proportional to the depth of the intersection.  In tight hallways, we may be forced to repeat this procedure to make sure that the new keyframe does not introduce new collisions.

We also must compute an orientation for the new keyframe.  We just use Q(t_mid) at the moment.

When the new keyframe has been inserted into the curve, that section of the curve is recomputed.  Again there is no guarantee that the curve is valid over that interval.  We have to scan over the interval again and repeat the process.